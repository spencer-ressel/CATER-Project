{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7cb7ed3-9950-473b-975c-e87051f26226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92aa45cf-7ca4-43a3-b2af-e687a0088912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reformat_time_dim(da):\n",
    "    \"\"\"\n",
    "    Takes xarray dataarray and converts its time dim to an array of numpy\n",
    "    \n",
    "    Inputs:\n",
    "    ----------------------------------------------------------------------\n",
    "    da: Xarray dataarray(set maybe?) \n",
    "    \n",
    "    Outputs:\n",
    "    ----------------------------------------------------------------------\n",
    "    da_reformat: Identical data to da, just different time dim format (numpy datetime46)\n",
    "    \"\"\"    \n",
    "    # Extract the numerical values of year, month, day, hour, minute, & second\n",
    "    years = da['time.year'].data\n",
    "    months = da['time.month'].data\n",
    "    days = da['time.day'].data\n",
    "    hours = da['time.hour'].data\n",
    "    minutes = da['time.minute'].data\n",
    "    seconds = da['time.second'].data\n",
    "    \n",
    "    # Make list of tuples of (y, m, d, H, M, S)\n",
    "    ymdHMS_list = []\n",
    "    for i, _ in enumerate(da['time.year'].data):\n",
    "        ymdHMS_list.append((years[i], months[i], days[i], hours[i], minutes[i], seconds[i]))\n",
    "\n",
    "    # Convert tuples to datetime string and then make array of numpy datetimes\n",
    "    dt_string_list = [f'{y:04d}-{m:02d}-{d:02d}T{H:02d}:{M:02d}:{S:02d}' \n",
    "                      for y, m, d, H, M, S in ymdHMS_list]\n",
    "    dt_array = np.array(list(map(np.datetime64, dt_string_list)))\n",
    "    da_reformatted = da.copy()\n",
    "    da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
    "    \n",
    "    return(da_reformatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67143aab-2360-4504-a794-ff8017a1051a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "korea_slice = dict(lat=slice(34, 38), lon=slice(125, 130))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09a7020f-f156-45fd-88ea-269efd07f111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_list =  ['ACCESS-ESM1-5', 'CanESM5', 'IPSL-CM6A-LR', 'MIROC6', 'MRI-ESM2-0']\n",
    "model_list = ['ACCESS-CM2', 'BCC-CSM2-MR', 'NorESM2-LM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9b06bf3-1db7-49be-9dbb-d3e60c2c96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_list = ['HadGEM3-GC31-LL', 'CNRM-CM6-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b40669-b4a1-4221-8f95-3dc0f0e4007d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/disk/tc/pangulo/CMIP6/ACCESS-CM2/historical/compiled_tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_18500101-20141231.nc',\n",
       " '/home/disk/tc/pangulo/CMIP6/ACCESS-CM2/historical/compiled_tasmax_day_ACCESS-CM2_historical_r2i1p1f1_gn_18500101-20141231.nc',\n",
       " '/home/disk/tc/pangulo/CMIP6/ACCESS-CM2/historical/compiled_tasmax_day_ACCESS-CM2_historical_r3i1p1f1_gn_18500101-20141231.nc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7860d2-e4e3-424b-9b6a-937b767cc958",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2\n",
      "Historical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging & Saving SSP\n",
      "[########################################] | 100% Completed |  3min  1.8s\n",
      "Hist-Nat\n",
      "Saving histnat\n",
      "[                                        ] | 0% Completed |  0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 50.5s\n",
      "Hist-GHG\n",
      "Saving histGHG\n",
      "[                                        ] | 0% Completed |  0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 50.7s\n",
      "BCC-CSM2-MR\n",
      "Historical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging & Saving SSP\n",
      "[########################################] | 100% Completed |  7min 27.0s\n",
      "Hist-Nat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving histnat\n",
      "[########################################] | 100% Completed |  5min  9.9s\n",
      "Hist-GHG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving histGHG\n",
      "[########################################] | 100% Completed |  5min 11.7s\n",
      "NorESM2-LM\n",
      "Historical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging & Saving SSP\n",
      "[########################################] | 100% Completed |  1min 59.9s\n",
      "Hist-Nat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving histnat\n",
      "[########################################] | 100% Completed |  1min 32.6s\n",
      "Hist-GHG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_937711/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving histGHG\n",
      "[########################################] | 100% Completed |  1min 31.4s\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_list:\n",
    "    print(model_name)\n",
    "    print('Historical')\n",
    "    historical_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/historical/compiled_tasmax_day_{model_name}_historical_r1*.nc')\n",
    "    historical_ds = xr.open_mfdataset(historical_files, chunks=dict(time=50)).sel(korea_slice).tasmax.squeeze().mean(('lat', 'lon'))\n",
    "    historical_ds = historical_ds.convert_calendar('noleap', align_on='year', use_cftime=True)\n",
    "    historical_ds = reformat_time_dim(historical_ds)\n",
    "    print('SSP')\n",
    "    ssp_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/ssp245/compiled_tasmax_day_{model_name}_ssp245_r1*.nc')\n",
    "    ssp_ds = xr.open_mfdataset(ssp_files, chunks=dict(time=50)).sel(korea_slice).tasmax.squeeze().mean(('lat', 'lon'))\n",
    "    ssp_ds = ssp_ds.convert_calendar('noleap', align_on='year', use_cftime=True)\n",
    "    ssp_ds = reformat_time_dim(ssp_ds)\n",
    "    with ProgressBar():\n",
    "        print('Merging & Saving SSP')\n",
    "        ssp_extended_ds = xr.concat((historical_ds, ssp_ds), dim='time').sortby('time')\n",
    "        file_name = f'/home/disk/p/pangulo/CATER-Project/HeatWave_Statistics/Data/{model_name}_ssp_extended_koreaTmax.nc'\n",
    "        if os.path.isfile(file_name):\n",
    "            os.remove(file_name)\n",
    "        ssp_extended_ds.to_netcdf(file_name, mode='w')\n",
    "        \n",
    "    print('Hist-Nat')\n",
    "    histnat_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/hist-nat/compiled_tasmax_day_{model_name}_hist-nat_r1*.nc')\n",
    "    histnat_ds = xr.open_mfdataset(histnat_files, chunks=dict(time=50)).sel(korea_slice).tasmax.squeeze().mean(('lat', 'lon'))\n",
    "    histnat_ds = histnat_ds.convert_calendar('noleap', align_on='year', use_cftime=True)\n",
    "    histnat_ds = reformat_time_dim(histnat_ds)\n",
    "    with ProgressBar():\n",
    "        print('Saving histnat')\n",
    "        file_name = f'/home/disk/p/pangulo/CATER-Project/HeatWave_Statistics/Data/{model_name}_hist-nat_koreaTmax.nc'\n",
    "        if os.path.isfile(file_name):\n",
    "            os.remove(file_name)\n",
    "        histnat_ds.to_netcdf(file_name, mode='w')\n",
    "        \n",
    "    print('Hist-GHG')\n",
    "    histGHG_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/hist-GHG/compiled_tasmax_day_{model_name}_hist-GHG_r1*.nc')\n",
    "    histGHG_ds = xr.open_mfdataset(histGHG_files, chunks=dict(time=50)).sel(korea_slice).tasmax.squeeze().mean(('lat', 'lon'))\n",
    "    histGHG_ds = histGHG_ds.convert_calendar('noleap', align_on='year', use_cftime=True)\n",
    "    histGHG_ds = reformat_time_dim(histGHG_ds)\n",
    "    with ProgressBar():\n",
    "        print('Saving histGHG')\n",
    "        file_name = f'/home/disk/p/pangulo/CATER-Project/HeatWave_Statistics/Data/{model_name}_hist-GHG_koreaTmax.nc'\n",
    "        if os.path.isfile(file_name):\n",
    "            os.remove(file_name)\n",
    "        histGHG_ds.to_netcdf(file_name, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b146c8cd-c9f0-4427-a096-b5d9bf90a96a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing SSP CNRM-CM6-1\n",
      "Missing Historical GFDL-CM4\n",
      "Missing SSP GFDL-CM4\n",
      "Missing histnat GFDL-CM4\n",
      "Missing histghg GFDL-CM4\n",
      "Missing Historical HadGEM3-GC31-LL\n",
      "Missing SSP HadGEM3-GC31-LL\n",
      "Missing histnat HadGEM3-GC31-LL\n",
      "Missing histghg HadGEM3-GC31-LL\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Code to check if compiled tasmax data exists\n",
    "##\n",
    "for model_name in model_list[1:]:\n",
    "    historical_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/historical/compiled_tasmax_day_{model_name}_historical*.nc')\n",
    "    if len(historical_files)==0:\n",
    "        print(f'Missing Historical {model_name}')\n",
    "    ssp_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/ssp245/compiled_tasmax_day_{model_name}_ssp245*.nc')\n",
    "    if len(ssp_files)==0:\n",
    "        print(f'Missing SSP {model_name}')\n",
    "        \n",
    "    histnat_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/hist-nat/compiled_tasmax_day_{model_name}_hist-nat*.nc')\n",
    "    if len(histnat_files)==0:\n",
    "        print(f'Missing histnat {model_name}')\n",
    "        \n",
    "    histGHG_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/hist-GHG/compiled_tasmax_day_{model_name}_hist-GHG*.nc')\n",
    "    if len(histGHG_files)==0:\n",
    "        print(f'Missing histghg {model_name}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
