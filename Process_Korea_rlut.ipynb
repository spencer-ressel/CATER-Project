{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7cb7ed3-9950-473b-975c-e87051f26226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92aa45cf-7ca4-43a3-b2af-e687a0088912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reformat_time_dim(da):\n",
    "    \"\"\"\n",
    "    Takes xarray dataarray and converts its time dim to an array of numpy\n",
    "    \n",
    "    Inputs:\n",
    "    ----------------------------------------------------------------------\n",
    "    da: Xarray dataarray(set maybe?) \n",
    "    \n",
    "    Outputs:\n",
    "    ----------------------------------------------------------------------\n",
    "    da_reformat: Identical data to da, just different time dim format (numpy datetime46)\n",
    "    \"\"\"    \n",
    "    # Extract the numerical values of year, month, day, hour, minute, & second\n",
    "    years = da['time.year'].data\n",
    "    months = da['time.month'].data\n",
    "    days = da['time.day'].data\n",
    "    hours = da['time.hour'].data\n",
    "    minutes = da['time.minute'].data\n",
    "    seconds = da['time.second'].data\n",
    "    \n",
    "    # Make list of tuples of (y, m, d, H, M, S)\n",
    "    ymdHMS_list = []\n",
    "    for i, _ in enumerate(da['time.year'].data):\n",
    "        ymdHMS_list.append((years[i], months[i], days[i], hours[i], minutes[i], seconds[i]))\n",
    "\n",
    "    # Convert tuples to datetime string and then make array of numpy datetimes\n",
    "    dt_string_list = [f'{y:04d}-{m:02d}-{d:02d}T{H:02d}:{M:02d}:{S:02d}' \n",
    "                      for y, m, d, H, M, S in ymdHMS_list]\n",
    "    dt_array = np.array(list(map(np.datetime64, dt_string_list)))\n",
    "    da_reformatted = da.copy()\n",
    "    da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
    "    \n",
    "    return(da_reformatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67143aab-2360-4504-a794-ff8017a1051a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_slice = dict(lon=slice(30, 180), lat=slice(0, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a7020f-f156-45fd-88ea-269efd07f111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_list =  ['ACCESS-ESM1-5', 'CanESM5', 'IPSL-CM6A-LR', 'MIROC6', 'MRI-ESM2-0', 'HadGEM3-GC31-LL', 'CNRM-CM6-1']\n",
    "\n",
    "model_list = [\n",
    "    'ACCESS-CM2',\n",
    "    # 'ACCESS-ESM1-5', \n",
    "    'BCC-CSM2-MR',\n",
    "    # 'CanESM5', \n",
    "    # 'CNRM-CM6-1',\n",
    "    # 'HadGEM3-GC31-LL', \n",
    "    # 'IPSL-CM6A-LR', \n",
    "    # 'MIROC6', \n",
    "    # 'MRI-ESM2-0', \n",
    "    'NorESM2-LM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eedebd1-be8e-4208-bc14-6b615ad4ab0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2\n",
      "Histnat\n",
      "Merging & Saving\n",
      "[#                                       ] | 3% Completed |  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1.2s\n",
      "BCC-CSM2-MR\n",
      "Histnat\n",
      "Merging & Saving\n",
      "[                                        ] | 0% Completed |  0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3.3s\n",
      "NorESM2-LM\n",
      "Histnat\n",
      "Merging & Saving\n",
      "[                                        ] | 0% Completed |  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.8s\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_list:\n",
    "    print(model_name)\n",
    "    print('Histnat')\n",
    "    histnat_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/hist-nat/compiled_rlut_Amon_{model_name}_hist-nat_r1*.nc')\n",
    "    histnat_ds = xr.open_mfdataset(histnat_files, chunks=dict(time=50, lat=50, lon=50)).sel(region_slice).rlut\n",
    "    histnat_ds = histnat_ds.convert_calendar('noleap', align_on='year', use_cftime=True)\n",
    "    histnat_ds = reformat_time_dim(histnat_ds).sel(time=slice('1/1/1950', None))\n",
    "   \n",
    "    with ProgressBar():\n",
    "        print('Merging & Saving')\n",
    "        file_name = f'/home/disk/p/pangulo/CATER-Project/HeatWave_Statistics/Data/{model_name}_hist-nat_rlut.nc'\n",
    "        if os.path.isfile(file_name):\n",
    "            os.remove(file_name)\n",
    "        histnat_ds.compute().to_netcdf(file_name, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7860d2-e4e3-424b-9b6a-937b767cc958",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2\n",
      "Historical\n",
      "SSP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging & Saving\n",
      "[########################################] | 100% Completed |  1.2s\n",
      "BCC-CSM2-MR\n",
      "Historical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSP\n",
      "Merging & Saving\n",
      "[#                                       ] | 2% Completed |  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3.2s\n",
      "NorESM2-LM\n",
      "Historical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSP\n",
      "Merging & Saving\n",
      "[########################################] | 100% Completed |  0.7s\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_list:\n",
    "    print(model_name)\n",
    "    print('Historical')\n",
    "    historical_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/historical/compiled_rlut_Amon_{model_name}_historical_r1*.nc')\n",
    "    historical_ds = xr.open_mfdataset(historical_files, chunks=dict(time=50, lat=50, lon=50)).sel(region_slice).rlut\n",
    "    historical_ds = historical_ds.convert_calendar('noleap', align_on='year', use_cftime=True)\n",
    "    historical_ds = reformat_time_dim(historical_ds).sel(time=slice('1/1/1950', None))\n",
    "    print('SSP')\n",
    "    ssp_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/ssp245/compiled_rlut_Amon_{model_name}_ssp245_r1*.nc')\n",
    "    ssp_ds = xr.open_mfdataset(ssp_files, chunks=dict(time=50, lat=50, lon=50)).sel(region_slice).rlut\n",
    "    ssp_ds = ssp_ds.convert_calendar('noleap', align_on='year', use_cftime=True)\n",
    "    ssp_ds = reformat_time_dim(ssp_ds).sel(time=slice(None, '1/1/2021'))\n",
    "    with ProgressBar():\n",
    "        print('Merging & Saving')\n",
    "        ssp_extended_ds = xr.concat((historical_ds, ssp_ds), dim='time').sortby('time')\n",
    "        file_name = f'/home/disk/p/pangulo/CATER-Project/HeatWave_Statistics/Data/{model_name}_ssp_extended_rlut.nc'\n",
    "        if os.path.isfile(file_name):\n",
    "            os.remove(file_name)\n",
    "        ssp_extended_ds.compute().to_netcdf(file_name, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32acdb42-2029-4cee-be94-8db503d75b79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2\n",
      "Hist-GHG\n",
      "Merging & Saving\n",
      "[#                                       ] | 3% Completed |  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1.2s\n",
      "BCC-CSM2-MR\n",
      "Hist-GHG\n",
      "Merging & Saving\n",
      "[                                        ] | 0% Completed |  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3.3s\n",
      "NorESM2-LM\n",
      "Hist-GHG\n",
      "Merging & Saving\n",
      "[####                                    ] | 11% Completed |  0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n",
      "/tmp/ipykernel_945230/3294554851.py:31: UserWarning: Converting non-nanosecond precision datetime values to nanosecond precision. This behavior can eventually be relaxed in xarray, as it is an artifact from pandas which is now beginning to support non-nanosecond precision values. This warning is caused by passing non-nanosecond np.datetime64 or np.timedelta64 values to the DataArray or Variable constructor; it can be silenced by converting the values to nanosecond precision ahead of time.\n",
      "  da_reformatted = da_reformatted.assign_coords(dict(time=dt_array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.7s\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_list:\n",
    "    print(model_name)\n",
    "    print('Hist-GHG')\n",
    "    histnat_files = glob.glob(f'/home/disk/tc/pangulo/CMIP6/{model_name}/hist-GHG/compiled_rlut_Amon_{model_name}_hist-GHG_r1*.nc')\n",
    "    histnat_ds = xr.open_mfdataset(histnat_files, chunks=dict(time=50, lat=50, lon=50)).sel(region_slice).rlut\n",
    "    histnat_ds = histnat_ds.convert_calendar('noleap', align_on='year', use_cftime=True)\n",
    "    histnat_ds = reformat_time_dim(histnat_ds).sel(time=slice('1/1/1950', None))\n",
    "   \n",
    "    with ProgressBar():\n",
    "        print('Merging & Saving')\n",
    "        file_name = f'/home/disk/p/pangulo/CATER-Project/HeatWave_Statistics/Data/{model_name}_hist-GHG_rlut.nc'\n",
    "        if os.path.isfile(file_name):\n",
    "            os.remove(file_name)\n",
    "        histnat_ds.compute().to_netcdf(file_name, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d08ef0-eecd-40a6-9b3d-13bfaffd35d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
